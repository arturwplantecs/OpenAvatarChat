default:
  logger:
    log_level: "INFO"
  service:
    host: "0.0.0.0"
    port: 8282
    cert_file: "ssl_certs/localhost.crt"
    cert_key: "ssl_certs/localhost.key"
  chat_engine:
    model_root: "models"
    handler_search_path:
      - "src/handlers"
    handler_configs:
      RtcClient:
        module: client/rtc_client/client_handler_rtc
        concurrent_limit: 1
      SileroVad:
        module: vad/silerovad/vad_handler_silero
        speaking_threshold: 0.5
        start_delay: 2048
        end_delay: 5000
        buffer_look_back: 5000
        speech_padding: 512
      SenseVoice:
        enabled: True
        module: asr/sensevoice/asr_handler_sensevoice
        model_name: "iic/SenseVoiceSmall"
      Edge_TTS:
        enabled: True
        module: tts/edgetts/tts_handler_edgetts
        voice: "en-US-AriaNeural"
      LLM_Bailian:
        enabled: True
        module: llm/openai_compatible/llm_handler_openai_compatible
        model_name: "gpt-4o-mini"
        enable_video_input: True # ensure your llm support video input
        # model_name: "gemini-2.0-flash"
        system_prompt: "You are an AI assistant, your name is QUARI. Always respond in English. Answer user questions briefly in 2-3 sentences and include appropriate punctuation in your responses. You can see through the camera - describe what you see only when explicitly asked to look, see, describe, or analyze the video/image/camera feed."
        api_url: "https://api.openai.com/v1"
        # api_url: 'http://127.0.0.1:11434/v1' # ollama
        # api_url: 'https://generativelanguage.googleapis.com/v1beta/openai/'
        api_key: "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"
      LiteAvatar:
        module: avatar/liteavatar/avatar_handler_liteavatar
        avatar_name: 20250408/sample_data
        fps: 25
        debug: false
        enable_fast_mode: false
        use_gpu: true
